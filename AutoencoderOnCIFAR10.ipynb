{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoencoderOnCIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2H44_5b2SXJ"
      },
      "source": [
        "Autoencoder build with convolutions on CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFMxzDjicTn8"
      },
      "source": [
        "!pip install progressbar2\n",
        "import progressbar\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_images = train_images.reshape((-1, 32, 32, 3)) / 255\n",
        "test_images = test_images.reshape((-1, 32, 32, 3)) / 255\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb8f7uLNcgpP"
      },
      "source": [
        "def build_model(reuse, is_training, name, **kwargs):\n",
        "  with tf.variable_scope(name, reuse=reuse):\n",
        "    \n",
        "    def instance_normalization(x):\n",
        "      return tf.contrib.layers.instance_norm(x)\n",
        "    \n",
        "    def layer(x, filter, strides, keep_prob, activation, name):\n",
        "      with tf.variable_scope(name):\n",
        "        filter = tf.get_variable('filter_weight', filter, initializer=tf.truncated_normal_initializer(stddev=5e-2, dtype=tf.float32), dtype=tf.float32)\n",
        "        x = tf.nn.conv2d(input=x, filter=filter, strides=strides, padding=\"SAME\")\n",
        "        x = instance_normalization(x)\n",
        "        x = activation(x)\n",
        "        x = x = tf.nn.dropout(x, keep_prob)\n",
        "        return x\n",
        "    \n",
        "    def layer_transpose(x, filter, strides, keep_prob, activation, name):\n",
        "      with tf.variable_scope(name):\n",
        "        x = tf.layers.conv2d_transpose(x, filters=filter[3], kernel_size=filter[1], strides=strides[1], padding=\"SAME\")\n",
        "        x = instance_normalization(x)\n",
        "        x = activation(x)\n",
        "        x = x = tf.nn.dropout(x, keep_prob)\n",
        "        return x\n",
        "      \n",
        "    def residual_block(x, in_filters, keep_prob, activation, name):\n",
        "      rx = x\n",
        "      x = layer(x, filter=[3, 3, in_filters, in_filters], strides=[1, 1, 1, 1], keep_prob=keep_prob, activation=activation, name=name+\"Residual1\")\n",
        "      x = layer(x, filter=[3, 3, in_filters, in_filters], strides=[1, 1, 1, 1], keep_prob=keep_prob, activation=activation, name=name+\"Residual2\")\n",
        "      return x + rx\n",
        "    \n",
        "    def encoder(x, keep_prob):\n",
        "      activation = tf.nn.relu\n",
        "      with tf.variable_scope(\"encoder\"): #supposse the input is 4 dimesional\n",
        "        x = layer(x, filter=[3, 3, 3, 60], strides=[1, 1, 1, 1], keep_prob=keep_prob, activation=activation, name=\"el1\")\n",
        "        x = layer(x, filter=[3, 3, 60, 120], strides=[1, 2, 2, 1], keep_prob=keep_prob, activation=activation, name=\"el2\")\n",
        "        x = layer(x, filter=[3, 3, 120, 240], strides=[1, 2, 2, 1], keep_prob=keep_prob, activation=activation, name=\"el4\")\n",
        "        x = layer(x, filter=[3, 3, 240, 8], strides=[1, 2, 2, 1], keep_prob=keep_prob, activation=activation, name=\"el3\")\n",
        "        return x\n",
        "\n",
        "    def decoder(x, keep_prob):\n",
        "      activation = tf.nn.relu\n",
        "      with tf.variable_scope(\"decoder\"):\n",
        "          x = layer(x, filter=[3, 3, 8, 240], strides=[1, 1, 1, 1], keep_prob=keep_prob, activation=activation, name=\"dl1\")\n",
        "          x = residual_block(x, in_filters=240, keep_prob=keep_prob, activation=activation, name=\"dr1\")\n",
        "          x = layer_transpose(x, filter=[3, 3, 240, 120], strides=[1, 2, 2, 1], keep_prob=keep_prob, activation=activation, name=\"dl2\")\n",
        "          x = layer_transpose(x, filter=[3, 3, 120, 60], strides=[1, 2, 2, 1], keep_prob=keep_prob, activation=activation, name=\"dl4\")\n",
        "          x = layer_transpose(x, filter=[3, 3, 60, 3], strides=[1, 2, 2, 1], keep_prob=keep_prob, activation=activation, name=\"dl3\")\n",
        "          return x\n",
        "    \n",
        "    class Model(object):\n",
        "      pass\n",
        "    \n",
        "    model = Model()\n",
        "  \n",
        "    model.X = tf.placeholder(dtype=tf.float32, shape=[None, None, None, None], name='X')\n",
        "    model.Y = tf.contrib.layers.flatten(inputs=model.X)\n",
        "    keep_prob = kwargs[\"keep_prob\"]\n",
        "\n",
        "    model.sampled = encoder(model.X, keep_prob)\n",
        "    model.dec = decoder(model.sampled, keep_prob)\n",
        "\n",
        "    model.unreshaped = tf.contrib.layers.flatten(inputs=model.dec)\n",
        "    model.img_loss = tf.reduce_sum(tf.squared_difference(model.unreshaped, model.Y), 1)\n",
        "    model.loss = tf.reduce_mean(model.img_loss)\n",
        "    model.optimizer = tf.train.AdamOptimizer(0.001).minimize(model.loss)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY45yTprr1vk"
      },
      "source": [
        "\n",
        "def print_reconstruction(n, batch, d):\n",
        "  m = 32\n",
        "  canvas_orig = np.empty((m * n, m * n, 3))\n",
        "  canvas_recon = np.empty((m * n, m * n, 3))\n",
        "  for i in range(n):\n",
        "      t = n\n",
        "      for j in range(n):\n",
        "          canvas_orig[i * m:(i + 1) * m, j * m:(j + 1) * m,:] = \\\n",
        "              batch[i*n+j].reshape([32, 32, 3])\n",
        "      for j in range(n):\n",
        "          canvas_recon[i * m:(i + 1) * m, j * m:(j + 1) * m,:] = \\\n",
        "              d[i*n+j].reshape([32, 32, 3])\n",
        "\n",
        "  print(\"Original Images\")\n",
        "  plt.figure(figsize=(n, n))\n",
        "  plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Reconstructed Images\")\n",
        "  plt.figure(figsize=(n, n))\n",
        "  plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n",
        "  plt.show()\n",
        "    \n",
        "def create_cnnae(**params):\n",
        "  tf.reset_default_graph()\n",
        "  \n",
        "  model_train = build_model(is_training=True, reuse=False, name = \"VA1\", **params)\n",
        "  model_test = build_model(is_training=False, reuse=True, name = \"VA1\", **params)\n",
        "  \n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        " \n",
        "    batch_size = params['batch_size']\n",
        "    steps_per_epoch =  params['elems'] //batch_size \n",
        "\n",
        "    print(steps_per_epoch, params['elems'], params['batch_size'])\n",
        "    for epoch in range(params['num_epochs']):\n",
        "      print(\"EPOCH {}:\".format(epoch))\n",
        "      loss_history1 = []\n",
        "      loss_history2 = []\n",
        "      progres = 0\n",
        "      with progressbar.ProgressBar(max_value = steps_per_epoch) as bar:\n",
        "        while True:\n",
        "          bar.update(progres)\n",
        "          progres += 1\n",
        "          if progres > steps_per_epoch:\n",
        "            break\n",
        "          step = epoch * steps_per_epoch + progres\n",
        "\n",
        "          batch = train_images[(progres-1)*batch_size:progres*batch_size]\n",
        "\n",
        "          ls1, _ = sess.run([model_train.loss, model_train.optimizer], feed_dict = {model_train.X: batch})\n",
        "\n",
        "          loss_history1.append(ls1)\n",
        "\n",
        "          if not progres % 200:\n",
        "              ls, d = sess.run([model_train.loss, model_train.dec], \\\n",
        "                                                     feed_dict = {model_train.X: batch})\n",
        "              print_reconstruction(3, batch, d)\n",
        "\n",
        "              print(\"AUTOENCODER 1: loss: {}, image_loss:{}\"\\\n",
        "                    .format(ls, np.mean(d)))\n",
        "\n",
        "            \n",
        "      print(\"Loss Function for AE1:\")\n",
        "      print(len(loss_history1))\n",
        "      plt.plot(loss_history1)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW48tt__r5Sm"
      },
      "source": [
        "batch_size = 32\n",
        "params={\n",
        "  'batch_size': batch_size,\n",
        "  'num_epochs': 20,\n",
        "  'elems': train_images.shape[0],\n",
        "  'keep_prob': 1\n",
        "}\n",
        "\n",
        "  \n",
        "create_cnnae(**params)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}